---
title: "DIFS analysis"
author: "Artjoms Šeļa"
date: '2022-07-22'
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggrepel)
library(tidytext)
library(paletteer)
df_fin <- read_tsv("data/df_fin_curves.tsv")
meta <- read_tsv("data/all_stars_meta.tsv") %>% select(-yearNormalized,-corpus)
df_res <- read_tsv("data/df_res.tsv")

#d <- read_tsv("data/logodds_curves.tsv")

#exp <- df_fin %>% select(char_id,d) %>% unique()

#write_tsv(exp,"data/artjom_d_measure.tsv")
```


### Curves-under-keywords

A simple, but not data-hungry approach to character distinctiveness:  

1. Calculate "keyness" for Character A vs "Others" in a drama
2. Arrange top $N$ keywords by amount of "keyness" 
3. Calculate the area under the curve. Guys who would have flatter curve decays are probably more distinctive (more words that describe them). That is it. That is our $d$ measure.

For keyness here I use [weighted log-odds] (https://bookdown.org/Maxine/tidy-text-mining/weighted-log-odds-ratio.html), but in principle anything will do.  

Legit characters are filter at $words > 2000$. In each log-odds calculation we upsample Character to "Other" lengths (probably will redo it to proper bootstrapping Ben's-way)  

$N$ keywords cut-off is 100 for every character (even if there is a tie in log-odds rank).  

The main script for analysis is `03_logodds_curves.R`, functions sit in `src/loo_distinct.R`.  

### Cleopatra & Anthony

Here is an example: Cleo girl has more distinctive words with values above the Anthony. Her area-under-curve would be of higher value.  

```{r}
df_fin %>% filter(playName=="antony-and-cleopatra") %>% filter(label %in% c("Antony_1", "Cleopatra_1")) %>%  ggplot(aes(rank,log_odds_weighted,color=label)) + geom_path() + theme_minimal() + scale_color_paletteer_d("wesanderson::Darjeeling1") + labs(x="word distinctivness rank")
```


### Bags of words

Good news is that together with distinctiveness measure $d$ we also have the corresponding words. Here are top 30 keywords per character, 50 top distinct characters from the whole corpus.

```{r}

labs <- df_fin %>% left_join(meta %>% select(playName,firstAuthor),by="playName") %>% group_by(label,d) %>% top_n(30,log_odds_weighted) %>% group_by(label,playName,firstAuthor,corpus,d) %>%   summarise(bag=paste(word,collapse = "_")) %>% group_by(corpus)  %>% top_n(50,d) %>% arrange(corpus)

knitr::kable(labs)
```



### D-measure vs. length

```{r}
df_fin %>% select(d,label,n,gender,corpus,eigenvector) %>% filter(gender %in% c("MALE","FEMALE")) %>% unique() %>% ggplot(aes(log(n),d,color=gender)) + geom_point(size=0.5,alpha=0.5) + geom_smooth(method="gam",se=F) + facet_wrap(~corpus)  +theme_minimal() + scale_color_paletteer_d("wesanderson::Darjeeling1")

```

### Shakespeare

Most distinctive characters for old fella Shake. Now, after standardizing curves at rank 100 and oversampling character, the distribution looks very similar to what we have with energy-distance bootstrapping magic.

```{r,fig.height=10,fig.width=5}
lost_girls <- c("Queen Elizabeth_1", "Queen Margaret_1","Cleopatra_1","Queen Margaret_1","	
Queen Margaret_2","Constance_10")
df_fin %>% filter(corpus=="shake") %>% select(d,char_id,label,n,gender,eigenvector) %>% unique() %>% mutate(gender=ifelse(label %in% lost_girls, "FEMALE", gender), gender=ifelse(is.na(gender), "MALE", gender)) %>% 
  ggplot(aes(d,reorder(label,d))) + theme_minimal() +
  geom_segment(aes(yend=label,x=150,xend=d),size=0.2) +
  geom_point(aes(color=n),size=2) + 
  #geom_label_repel(data=labs,aes(label=bag),nudge_y = 100,size=3) + 
  theme(axis.text.y = element_text(hjust = 1,size=6))  + facet_grid(scales = "free_y",space="free_y",rows=vars(gender)) + scale_color_paletteer_c("gameofthrones::targaryen2") +
  scale_x_continuous(limits=c(150,400),expand = c(0, 0)) 

```
### Female vs. male keywords all 


```{r}
library(tidylo)
allstars <- read_tsv("data/allstars_clean.tsv") %>% 
  mutate(gender = ifelse(gender == "MAE","MALE",gender))

a_tok <- allstars %>% unnest_tokens(input=cleanText, output=word) %>% group_by(corpus) %>% group_split()

list_df <- vector(mode="list",length=length(a_tok))

for (i in 1:length(a_tok)) {
  cr=a_tok[[i]]$corpus %>% unique()
  
  fr_t <- a_tok[[i]] %>% filter(gender != "UNKNOWN") %>% 
  group_by(gender) %>%
# sample_n(500000,replace=T) %>%
  count(gender,word) %>% 
  bind_log_odds(gender,word,n)

  fr_top <- fr_t %>%
  group_by(gender) %>%
  top_n(200) %>% 
  arrange(gender, -log_odds_weighted) %>% mutate(corpus=cr)
  
  list_df[[i]] <- fr_top

}



```
Let's look at 20 most distinctive words in each corpus.  
These are weird: women words look fine, but men words are full of toponyms and proper nouns.
Is it a bug or a feature? If a feature, consider this: women speak less about the non-immediate world, refer to outside characters etc.? Would be consistent with "loving"/"feeling" niche for women chars.  Still, might be some log-odds failure that i don't see. 

**French:**

```{r}
fr <- list_df[[1]] %>% group_by(gender) %>% top_n(20,log_odds_weighted)

knitr::kable(fr)
```
  

**German:  **

```{r}
ger <- list_df[[2]] %>% group_by(gender) %>% top_n(20,log_odds_weighted)

knitr::kable(ger)
```  

  
**Russian:**  


```{r}
rus <- list_df[[3]] %>% group_by(gender) %>% top_n(20,log_odds_weighted)

knitr::kable(rus)
```

**Shakespeare:**


```{r}

shk <- list_df[[4]] %>% group_by(gender) %>% top_n(20,log_odds_weighted)

knitr::kable(shk)
```


```{r,eval=F}
p_fr <- fr_top %>%
 arrange(gender, log_odds_weighted) %>%
 mutate(pos_y=row_number()) %>%
 mutate(pos_x=ifelse(gender=="FEMALE",-1,1)) %>%
 ggplot(aes(pos_x,pos_y)) + 
 geom_text(aes(label=word,color=gender)) + xlim(-5,5) + theme_void() +
  scale_color_paletteer_d("basetheme::clean")

```
  
```{r}
## saving log odds in a tsv

loo_df <- list_df %>% bind_rows()

write_tsv(loo_df,file="data/gender_log_odds_top200.tsv")

```

  
## Character unmasking

The small part of supervised "unmasking" by character. The same idea: look at how quickly accuracy (SVM, leave-one-out) curves deteriorate when you remove top performing feature, one by one.  

TL;DR. It works! Word lists are similar to Keyness words, but overall not enough data for too much resources.    

```{r}
df_res %>% select(char_id,label,round,acc) %>% ggplot(aes(round,acc,color=label)) + geom_path() + theme_minimal() + scale_color_paletteer_d("basetheme::brutal") + facet_wrap(~label)
```
  
First 30 removed features for Cleo in SVM unmasking:  

```{r}
s <- df_res %>% filter(label=="Cleopatra") %>% select(d_words,acc)

knitr::kable(s)
```
  
Top 30 keywords for Cleo girl.

```{r}
df1 <- df_fin %>% filter(label=="Cleopatra_1") %>%
  select(word,log_odds_weighted)

knitr::kable(df1[1:30,])

```

## Formal models

```{r energy dists,eval=F}
library(brms)

#d_df <- df_fin %>% left_join(meta,by="playName") %>% select(d,label,n,gender,corpus,yearNormalized,firstAuthor,normalizedGenre,eigenvector) %>% filter(gender %in% c("MALE","FEMALE")) %>% unique()

d_df <- read_csv("data/consolidated_energy.csv")

```

What is the influence of character's gender on distinctiveness scores across traditions, conditioned on share of dialogue they have (sample size)? We aim at the multilevel multiple regression with partial pooling of estimates per each individual author:

```
D ~ Gender * Corpus + Size + (1 + Gender + Corpus |Author)
```

However, we also build smaller models to show that their predictions are worse (cross validation)

``

```{r,eval=F}
d <- d_df %>% mutate(D=VersusOther50,
            S=PctDialog,
            logD=log(D),
            logS=log(S),
            G=gender)


## baseline D ~ G*corpus
m1 <- brm(formula = D ~ G*corpus,
          data=d,
          cores = 4,file = )
```


```{r,eval=F}
plot(d$n,d$d)

pp_check(m1_gender_size)
summary(m1_gender_size)
conditional_effects(m1_gender_size, "gender:corpus")

```

```{r,eval=F}
m2 <- brm(formula = d ~ gender*corpus + gender*n,data=d,cores = 4)

```

```{r,eval=F}
pp_check(m2)
summary(m2)
conditional_effects(m2)
```

```{r,eval=F}
d_zeroshake <- d %>% filter(corpus != "shake")

m3 <- brm(formula = d ~ gender*corpus*n + (1 + gender|firstAuthor),data=d_zeroshake,cores = 4)

pp_check(m3)
summary(m3)
conditional_effects(m3)
```


```{r,eval=F}
ranef(m3, groups="firstAuthor", probs = 0.5)

d_zeroshake$firstAuthor %>% unique() %>% length()

m3 %>%
  tidybayes::spread_draws(r_firstAuthor[,genderMAlE]) #%>%
  # add the grand mean to the group-specific deviations
  mutate(mu = b_cw_Intercept + r_site__cw) %>%
  ungroup() %>%
  mutate(site = str_replace_all(site, "[.]", " ")) %>% 
  
  # plot
  ggplot(aes(x = mu, y = reorder(site, mu))) +
  geom_vline(xintercept = fixef(k_fit_brms)[1, 1], color = "#839496", size = 1) +
  geom_vline(xintercept = fixef(k_fit_brms)[1, 3:4], color = "#839496", linetype = 2) +
  geom_halfeyeh(.width = .5, size = 2/3, fill = "#859900") +
  labs(x = expression("Cottonwood litterfall (g/m^2)"),
       y = "BEMP sites ordered by mean predicted litterfall") +
  theme(panel.grid   = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0),
        text = element_text(family = "Ubuntu")) 
```

